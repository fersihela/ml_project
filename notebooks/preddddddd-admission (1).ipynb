{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71124fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.4532 - loss: 1.5049\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6182 - loss: 1.1247\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5776 - loss: 1.0931 \n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5844 - loss: 1.2139 \n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5527 - loss: 1.1724 \n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6399 - loss: 1.0454 \n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5736 - loss: 1.1023 \n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5735 - loss: 1.1846\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6667 - loss: 1.0328 \n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6390 - loss: 1.1127 \n",
      "\n",
      "ğŸ“ Top orientations recommandÃ©es :\n",
      "1. INFO â€” 78.22%\n",
      "2. TELCOMM â€” 14.21%\n",
      "3. ELECTRO â€” 4.78%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate, Dropout\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# === Connexion PostgreSQL ===\n",
    "from sqlalchemy import create_engine, text\n",
    "host = os.getenv(\"DB5_HOST\")\n",
    "port = os.getenv(\"DB5_PORT\")\n",
    "database = os.getenv(\"DB5_NAME\")\n",
    "username = os.getenv(\"DB5_USER\")\n",
    "password = os.getenv(\"DB5_PASSWORD\")\n",
    "db_url = f\"postgresql+psycopg2://{username}:{password}@{host}:{port}/{database}\"\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# === RequÃªte des donnÃ©es ===\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    c.sexe,\n",
    "    c.pays,\n",
    "    c.\"situationEconomique\",\n",
    "    f.\"moy_bac_et\",\n",
    "    d.\"Section\",\n",
    "    d.\"Type\",\n",
    "    f.\"score_final\",\n",
    "    c.resultat,\n",
    "    c.orientation\n",
    "FROM \"factadmission\" f\n",
    "JOIN \"DIM_CANDIDAT\" c ON f.\"fkCandidat\" = c.\"pkcandidat\"\n",
    "JOIN \"dim_diplome\" d ON f.\"fkDiplome\" = d.\"PkDiplome\"\n",
    "WHERE d.\"Type\" = 'bac';\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# === Encodage des colonnes ===\n",
    "categorical_cols = ['sexe', 'pays', 'situationEconomique', 'Section', 'orientation']\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# === Features et Target ===\n",
    "X = df[['sexe', 'pays', 'situationEconomique', 'moy_bac_et', 'Section']]\n",
    "y = df['orientation']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# === Conversion des types pour Ã©viter les erreurs avec TensorFlow ===\n",
    "X_train = X_train.astype({\n",
    "    'sexe': 'int32',\n",
    "    'pays': 'int32',\n",
    "    'situationEconomique': 'int32',\n",
    "    'Section': 'int32',\n",
    "    'moy_bac_et': 'float32'\n",
    "})\n",
    "X_test = X_test.astype({\n",
    "    'sexe': 'int32',\n",
    "    'pays': 'int32',\n",
    "    'situationEconomique': 'int32',\n",
    "    'Section': 'int32',\n",
    "    'moy_bac_et': 'float32'\n",
    "})\n",
    "y_train = y_train.astype('int32')\n",
    "y_test = y_test.astype('int32')\n",
    "\n",
    "# === Embedding Info ===\n",
    "embedding_info = {col: df[col].nunique() for col in ['sexe', 'pays', 'situationEconomique', 'Section']}\n",
    "\n",
    "# === Inputs ===\n",
    "input_sexe = Input(shape=(1,))\n",
    "input_pays = Input(shape=(1,))\n",
    "input_situation = Input(shape=(1,))\n",
    "input_section = Input(shape=(1,))\n",
    "input_moyenne = Input(shape=(1,))\n",
    "\n",
    "# === Embeddings ===\n",
    "embed_sexe = Embedding(input_dim=embedding_info['sexe']+1, output_dim=2)(input_sexe)\n",
    "embed_pays = Embedding(input_dim=embedding_info['pays']+1, output_dim=4)(input_pays)\n",
    "embed_situation = Embedding(input_dim=embedding_info['situationEconomique']+1, output_dim=4)(input_situation)\n",
    "embed_section = Embedding(input_dim=embedding_info['Section']+1, output_dim=4)(input_section)\n",
    "\n",
    "# === Flatten ===\n",
    "flat_sexe = Flatten()(embed_sexe)\n",
    "flat_pays = Flatten()(embed_pays)\n",
    "flat_situation = Flatten()(embed_situation)\n",
    "flat_section = Flatten()(embed_section)\n",
    "\n",
    "# === Concatenation ===\n",
    "concat = Concatenate()([flat_sexe, flat_pays, flat_situation, flat_section, input_moyenne])\n",
    "\n",
    "# === RÃ©seau de neurones ===\n",
    "x = Dense(128, activation='relu')(concat)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "output = Dense(len(df['orientation'].unique()), activation='softmax')(x)\n",
    "\n",
    "# === Compilation ===\n",
    "model = Model(inputs=[input_sexe, input_pays, input_situation, input_section, input_moyenne], outputs=output)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# === EntraÃ®nement ===\n",
    "model.fit([ \n",
    "    X_train['sexe'], \n",
    "    X_train['pays'], \n",
    "    X_train['situationEconomique'], \n",
    "    X_train['Section'], \n",
    "    X_train['moy_bac_et']\n",
    "], y_train, epochs=10, verbose=1)\n",
    "\n",
    "# === PrÃ©diction avec nouvelles donnÃ©es (y compris valeur inconnue gÃ©rÃ©e) ===\n",
    "nouveau_candidat = {\n",
    "    'sexe': 'F',\n",
    "    'pays': 'MA',  # Nouvelle valeur\n",
    "    'situationEconomique': 'Riche',  # Nouvelle valeur\n",
    "    'Section': 'science',  # Nouvelle valeur\n",
    "    'moy_bac_et': 15.7\n",
    "}\n",
    "\n",
    "def safe_transform(le, value):\n",
    "    if value in le.classes_:\n",
    "        return le.transform([value])[0]\n",
    "    else:\n",
    "        le.classes_ = np.append(le.classes_, value)\n",
    "        return le.transform([value])[0]\n",
    "\n",
    "encoded = {\n",
    "    'sexe': safe_transform(label_encoders['sexe'], nouveau_candidat['sexe']),\n",
    "    'pays': safe_transform(label_encoders['pays'], nouveau_candidat['pays']),\n",
    "    'situationEconomique': safe_transform(label_encoders['situationEconomique'], nouveau_candidat['situationEconomique']),\n",
    "    'Section': safe_transform(label_encoders['Section'], nouveau_candidat['Section']),\n",
    "    'moy_bac_et': nouveau_candidat['moy_bac_et']\n",
    "}\n",
    "\n",
    "pred = model.predict([\n",
    "    np.array([encoded['sexe']]),\n",
    "    np.array([encoded['pays']]),\n",
    "    np.array([encoded['situationEconomique']]),\n",
    "    np.array([encoded['Section']]),\n",
    "    np.array([encoded['moy_bac_et']])\n",
    "], verbose=0)\n",
    "\n",
    "top_k = pred[0].argsort()[-3:][::-1]\n",
    "orientations = label_encoders['orientation'].inverse_transform(top_k)\n",
    "\n",
    "print(\"\\nğŸ“ Top orientations recommandÃ©es :\")\n",
    "for i, (o, prob) in enumerate(zip(orientations, pred[0][top_k])):\n",
    "    print(f\"{i+1}. {o} â€” {round(prob * 100, 2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46c63033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ModÃ¨le enregistrÃ© en 'modele_orientation.h5'\n"
     ]
    }
   ],
   "source": [
    "model.save(\"modele_orientation.h5\")\n",
    "print(\"âœ… ModÃ¨le enregistrÃ© en 'modele_orientation.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a370cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Encoders enregistrÃ©s en 'label_encoders.joblib'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(label_encoders, \"label_encoders.joblib\")\n",
    "print(\"âœ… Encoders enregistrÃ©s en 'label_encoders.joblib'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95529b00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
